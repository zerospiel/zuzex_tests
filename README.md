# README

В этой документации указаны основные принципы работы каждого из репозиториев, на что следует обратить внимание, как работать с кодогенерацией, как работать на фронте, что делать при работе над фичей одновременно в нескольких репозиториях.

Также перечислены общие дальнейшие действия, которые желательно бы было сделать, что происходит на сервере и как там устроен проект, некоторые моменты по поводу CI и ещё пара мелочей.

При возникновении вопросов можно [писать на мой личный email](mailto:ww@bk.ru).

## Содержание

- [Код и принцип работы](#code-main)
  - [Репозитории](#repos)
    - [ADDRESS](#address)
    - [API](#api)
      - [Go-Swagger](#api-swagger)
    - [APP](#app)
      - [Go-Swagger](#app-swagger)
      - [Front-end](#app-front)
    - [FETCHER](#fetcher)
    - [IMPORTER](#importer)
    - [INDEXER](#indexer)
    - [IO](#io)
    - [MUNROLL](#munroll)
    - [NORMALIZER](#normalizer)
    - [PREIMPORT](#preimport)
    - [SCRAPER](#scraper)
    - [UTILS](#utils)
- [Deploy](#deploy)
  - [CI](#wercker)
- [Сервер (DigitalOcean)](#serverside)
  - [Dokku](#dokku)
  - [Docker](#docker)
- [Сборка, запуск, разработка](#build-main)
  - [Установка](#prereq)
  - [Сборка проекта](#build-project)
  - [Разработка в нескольких репозиториях](#dep-work)
- [TODO](#todo)
  - [Оркестрация](#swarm)
  - [Разбан сервера](#crawlera)
  - [Preimport as a Service](#preimport-aas)
  - [Normalizer as a Service](#normalizer-aas)
  - [Включить PaperTrail](#paper-logger)
- [Другие README](#other-readme)

<div id="code-main"/>

## Код и принцип работы

Здесь и далее перечислены основные репозитории и особенности их работы. Репозиторий **normapi** не указан в связи с устареванием.

Все репозитории были обновлены и частично пересобраны для того, чтобы их можно было собирать и всё работало (до этого сборка была практически неработающая с невозможностью каких-либо обновлений зависимостей). Указанный выше **normapi** также пересобран и обновлён.

*Все репозитории используют менеджер пакетов **[dep][dep-link]***.

<div id="repos"/>

## Репозитории

В проекте имеется основной репозиторий, который выполняет роль главного бэк-энда и в нём же лежит фронт-энд — это репозиторий **[APP](#app)**. Также репозиторий **[API](#api)**, который содержит в себе необходимые для сервера и микросервисов модели, а также код для работы с миграциями.

Остальные репозитории являются *микросервисами*, которые общаются между собой с помощью менеджера сообщений **[RabbitMQ]**.

**Общая схема работы** простая:

1. Каждый микросервис слушает какую-то/какие-то определённые очереди.
2. Пользователь создал задачу, Задача передаётся на сервер.
3. Сервер обрабатывает задачу и передаёт обработку микросервису A через какую-то из очередей.
4. Сервис A получает задачу, обрабатывает данные и посылает промежуточный результат микросервису B через какую-то из очередей для дальнейшей обработки.
5. Микросервис B получает данные из слушаемой очереди, обрабатывает их и по необходимости передаёт куда-то ещё.

**Простой пример**:

1. Пользователь на фронте меняет количество «потоков».
2. Сервер получил число, обработал типы и передал значение в очередь микросервису **[IO](#io)**.
3. Микросервис **IO** получил данные из очереди, обработал их и передал очереди микросервиса **[Scraper](#scraper)**.
4. Микросервис **Scraper** получил данные из очереди, использовав полученное число, изменил ёмкость семафора пула задач.

### Замечание про микросервисы

На сервере на текущий момент имеются микросервисы не под все репозитории (см. **[Normalizer as a Service](#normalizer-aas)** и **[Preimport as a Service](#preimport-aas)**), поэтому количество запущенных бинарников на локальной машине и количество контейнеров с сервисами на сервере могут отличаться в бóльшую сторону на локальной машине. В этом нет ничего страшного, просто стоит знать об этой особенности.

### Замечание про детализированность описаний

Я успел «плотно» поработать лишь с несколькими сервисами, поэтому где-то для сервиса будет намного более детальное описание, а где-то лишь то, с чем я работал при обновлении и пересборке репозиториев.

>*В любом случае, обязательно следует предварительно ознакомиться с кодом и общими принципами работы основных файлов (например, отвечающих за **build** бинарника)*.

<div id="address"/>

## `Address`

Сервис, который отвечает за распознавание адресов. Использует несколько API сторонних сервисов (Google Maps, Smarty Streets).

### Детали работы `Address`

Сервис имеет несложную структуру. Используется 3 различных карточных сервиса:

- [SmartyStreets];
- [Google Maps];
- [YAddress];

Методы по нормализации адреса работают следующим образом:

1. Сначала SmartyStreets пробегается со своим поиском. Если заданный адрес не содержит в себе штата, города и индекса, то SS занимается свободным поиском и валидацией адреса, в другом же случае поиск для адресов США не осуществляется (потому что все данные имеются).
2. Если SS фейлится с поиском/валидацией адреса, то в работу вступают Google Maps (*API для Place*), которые ищут заданный адрес. Если фейлится Place API, то используется *Geocode API*.
3. После поиска GM опять работает SS с адресом, который отдали GM. Если опять фейлится валидация, то из полученного адреса удаляются город и штат, п.2 повторяется.
4. Если опять проиходит фейл, то используется *Google Custom Search API* и опять вызывается API SS.
5. Если и п.4 фейлится, то вызывается *API YAddress*, происходит, насколько возможно, коррекция адреса и опять вызывается SS для нормализации адреса.

### Тесты `Address`

Для директорий `Client`, `Provider`, `Utils` имеются тесты, но они по большей части нерабочие, я их не правил, поэтому надо быть внимательным при работе с кодом, либо переписать тесты.

>***Замечание***: *Сейчас почти все тесты существуют с вызовом `t.Skip()`!*

### Ключи API `Address`

В этом репозитории (в конфиге) и в настройках контейнера [на сервере](#serverside) ***используются ключи первого разработчика*** для Google Maps и для SmartyStreets. В случае второго сервиса ключ от бесплатного аккаунта, поэтому SmartyStreets работают ***только с адресами США***.

В идеале надо создать свои собственные ключи и отдать аккаунты клиенту.

### **Индус в `Address`**

Многие изменения в коде в этом репозитории были сделаны индусом, поэтому многие функции, методы или какие-то строки кода могут показаться абсолютно нелогичными (с точки зрения исполнения, именования или вызова).

В этом репозитории я избавлялся от откровенно ужасных кусков кода и допилил лишь пару функций.

<div id="api"/>

## `API`

Репозиторий с сгенерированными моделями для использования на бэке сервера и в других микросервисах, основная программа для создания миграций.

### Детали работы `API`

В этом репозитории почти нет особых деталей работы, миграции сидят на пакете [SQLMigrate]. Миграции работают в связке с пакетом [Go-Bindata], которому необходимо скормить все файлы `*.sql` из директории `migrations` и манифест `swagger`:

```sh
$ go-bindata -pkg pgtransp -o path_to_api/client/pgtransp/bindata.go path_to_api/fixed.yaml $(find path_to_api/client/pgtransp/migrations -type f -name "*.sql")
# отдаёт пакету манифест и все миграции
# команду не следует запускать руками, она присутствует в Makefile
```

Сгенерированный файл `bindata.go` и используется при создании миграций.

Следует обратить внимание на пакет `pgtransp`, в котором находится код для обработки различных API запросов, например запросов `PATCH`, `DELETE` или `GET`. В файле `query.go` написаны методы для обработки структур, объявленных в манифесте `swagger`, чтобы сматчить их с таблицами БД.

>***Замечание***: *на бэке я написал пару методов, они что-то делают с БД, я писал прямые `SQL` запросы к БД, не понимая того, каким образом работают условные методы удаления без фактического обращения к базе. Потратив пару минут, я обнаружил, что имеются файлы типа `delete_*.go` или `post_*.go` в этом репозитории, где на самом деле и происходит обращение к базе (через ORM). Это замечание стоит перепроверить, если всё так, то методы удаления, патча или обычного поста ­— следует обрабатывать в репозитории `API`, таким образом унифицируя все обработчики на бэке.*

### Тесты `API`

Имеется обширное покрытие тестами почти всех используемых пакетов, тесты рабочие, но следует учесть два фактора:

1. Тесты есть не для всех функций.
2. Тесты прогоняются на маленьком количестве данных (кейсов).

В связи с этим следует либо **дописывать тесты по мере использования** и модификации репозитория, либо действовать на свой страх и риск, даже если все тесты успешно завершаются.

### Использование CLI `API`

```sh
$ api-cli init
# обычная инициализация по дефолту к БД с названием snl, не несёт полезной функции
$ api-cli migrate
# применяет миграции из директории `client/pgrtransp/migrations` по дефолту к БД с названием snl
$ api-cli migrate down
# откатить миграции
```

<div id="api-swagger"/>

## Go-Swagger `API`

Проект активно использует кодогенерацию через [Go-Swagger], в частности репозиторий `API`, в котором генерируются все модели и базовые операции над ними, которые в дальнейшем используются в `APP` и остальных микросервисах. Немного ознакомиться с тем, что такое Swagger, Go-Swagger и Open API — можно на [официальном сайте с документацией][swagger-off] или [в этом блоге][swagger-blog].

В этом репозитории необходимо лишь объявлять новые модели (структуры) и операции (функции), генерируя таким образом `REST API` клиента.

*Сложный пример сложной структуры*:

```yaml
...
definitions:
  ...
  BackgroundTaskSerializer:
    properties:
      id:
        format: long
        type: integer
      created_by:
        format: long
        type: integer
      action:
        type: string
        enum:
          - upload
          - export
          - restart
          - run_bots
          - munroll
          - import
          - export_leads
          - reindex_property
          - reindex_property_all
          - reindex_addresses_all
          - fetch
          - run_bots_deceased_dade
          - run_bots_miami
          - run_bots_broward
          - run_bots_duval
          - run_bots_orange
          - run_bots_osceola
          - run_bots_palm-beach
          - run_bots_pasco
          - run_bots_pinellas
          - run_bots_seminole
          - run_bots_volusia
          - run_bots_hillsborough
          - run_bots_realtdm

      done:
        type: boolean
      hidden:
        type: boolean
      sent:
        type: boolean
      scheduled_on:
        type: string
        format: date-time
      recurrent_in:
        type: integer
        format: long
      total:
        format: int
        type: integer
      processed:
        format: int
        type: integer
      payload:
        type: object
        properties:
          import:
            $ref: '#/definitions/ImportUploadSerializer'
          files:
            type: array
            items:
              type: string
          email:
            type: string
          records:
            type: array
            items:
              type: string
          uploads:
            type: array
            items:
              type: integer
              format: int
          upload:
            $ref: '#/definitions/ScrapperUploadSerializer'
          appraisal:
            type: boolean
          bills:
            type: boolean
          preimport:
            type: boolean
          replace:
            type: boolean
          fullUploads:
            type: array
            items:
              $ref: '#/definitions/ScrapperUploadSerializer'
          munroll:
            $ref: '#/definitions/MunrollUploadSerializer'
          criteria:
            type: string
          leads:
            $ref: '#/definitions/ExportLeadsSerializer'
          ids:
            type: array
            items:
              type: integer
              format: int
        additionalProperties:
          type: object
      result:
        type: object
        additionalProperties:
          type: object
      err:
        type: string
      created_on:
        type: string
        format: date-time
      updated_on:
        type: string
        format: date-time
    required:
    - created_by
    - action
    - err
    - done
    - sent
    - hidden
    - created_on
    - updated_on
    - scheduled_on
    title: BackgroundTaskSerializer
    type: object
  ...
```

*Пример простой операции*:

```yaml
...
paths:
  ...
  /api/background/tasks/delete:
    delete:
      x-table: background_task
      description: Destroy `Background Task` ((plain-detail))
      operationId: Delete_Background_Task_DELETE_
      parameters:
      - name: identifiers
        in: body
        schema:
          type: array
          items:
            type: integer
            format: long
      produces:
      - application/json
      responses:
        "204":
          description: No Content
        "400":
          description: Error
          schema:
            $ref: '#/definitions/Error'
  ...
```

При пересборке репозиториев я столкнулся с тем, что возникала коллизия в названиях пакетов в репозитории `APP` с его собственными пакетами. Использовался некорректный пакет для некоторых операций, где объявлялись сложные возвращаемые значения.

Из-за этого эти значения не были видны. Я обернул их в рекурсивную структуру. Несмотря на то, что в примере выше также используются рекурсивные структуры, файлы генерировались некорректно, пришлось немного поменять обработку манифеста для правильной обработки структур и последующего их использования с базой.

*Пример простой рекурсивной структуры в* `definitions`:

```yaml
...
paths:
  ...
  BackgroundTaskRespOK:
    properties:
      count:
        format: long
        type: integer
      results:
        items:
          $ref: '#/definitions/BackgroundTaskSerializer'
        type: array
    title: PListBackgroundTaskSerializer
    type: object
  ...
```

> ***Совет***: *Из-за того, что файл манифеста может показаться большим, следует использовать [онлайн-редактор][swagger-editor], который сразу подскажет имеются ли какие-то ошибки в новой объявленной структуре или операции.*

После описания манифеста, остаётся лишь сгенерировать файлы клиентского API. Сделать это можно руками или же через билд проекта (см. [сборку проекта](#build-project)):

```sh
$ $(GOBIN)/swagger generate client -A api -f path_to_api/fixed.yaml
# будут сгенерированы все необходимые структуры и их методы на основе указанного файла
```

<div id="app"/>

## `APP`

Главный репозиторий, где лежит и частично генерируется (через `webpack`) front-end, а также обрабатываются запросы `REST API`. Все модели и сам манифест `swagger` из репозитория `API` лежат здесь. Также в этом репозитории есть свой собственный манифест `swagger`, о нём [ниже](#app-swagger).

Модели `API` клиента здесь не генерируются, а используются из репозитория `API`. Чтобы они были используемы, при билде я произвожу следующую хитрую операцию:

```sh
$ find path_to_app/rest/operations -type f -name "*.go" -print0 | xargs -0 sed -i '/\tmodels/s#/app/models#/api/models#g'
# эту команду не надо запускать руками, она заменяет все использования пакетов моделей (структур) app в операциях на api, в app этих файлов по итогу нет, а в api они есть, в этом репозитории они цепляются из vendor'а
```

### Детали работы `APP`

Главный пакет — `handlers`, в котором лежат все обработчики `REST API`, эти обработчики необходимо вешать на сгенерированные функции операций в файле `configure_app.go` пакета `rest`. Как только будет написан обработчик и объявлен в этом файле — новый метод API сразу же заработает.

Маленький пакет `claims` помогает в авторизации, генерации и верификации токенов авторизации.

В пакете `operations` лежат сгенерированные для сервера функции, их не требуется рассматривать.

>***Замечание***: *на текущий момент в проекте имеется менее 50% готовых обработчиков для сгенерированных функций.*

Следует обратить внимание на файл `handlers.go` в пакете `handlers`, в нём присутствует конструктор, пара полезных методов и метод `pushTask()`, который и отвечает за **передачу данных от сервера к другим микросервисам**. Конкретно этот метод передаёт данные очереди `actions` — дефолтное название очереди сервиса [IO](#io).

Присутствуют 2 пакета для бинарников:

1. Бинарник `app-cli`, который используется для расширения манифеста `swagger` текущего репозитория манифестом из репозитория `API`.

```sh
$ app-cli extend path_to_app/vendor/bitbucket.org/dadebotsdb/api/fixed.yaml > path_to_app/swagger.yaml
# эту команду также не следует запускать руками, пример того, для чего нужен бинарник `app-cli`
```

2. Бинарник `app-server`, который и **является сервером**, у него есть несколько ключей

```sh
$ app-server --help
# вывод возможных ключей запуска сервера
$ app-server --host="localhost" --port 50000 --scheme http
# стандартный пример, который используется при выполнении `make serve`
# присутствует возможность запуска https, но на локалке это не имеет смысла
# на сервере я уже настроил всё для работы по HTTPS по дефолту
```

Более подробно про работу со [Swagger](#app-swagger) и [фронтом](#app-front) читать в соответствующих разделах.

### Тесты `APP`

**Тесты в этом репозитории отсутствуют** (за исключением 1 файла с 1 функцией). Их следует написать самому.

### Ключи API `APP`

В этом репозитории используются ключи API как минимум одного сервиса, `Google+`, для `OAuth`-авторизации. Все настройки и ключи расположены в проекте `DADEBOTSDB` в аккаунте `mmorgoev@zuzex.com`. За доступом обращаться к руководителю WEB-отдела или системному администратору.

<div id="app-swagger"/>

## Go-Swagger `APP`

Манифест `swagger` в этом репозитории устроен проще, чем в репозитории `API`. Здесь требуется добавлять лишь те операции, которых нет в манифесте `API`, при этом **модели добавлять не имеет смысла**, потому что они скипаются при билде.

*Пример добавления операции*:

```yaml
...
paths:
  ...
  /api/token:
    post:
      consumes:
      - application/x-www-form-urlencoded
      description: Get JWT token with credentials of oauth token
      operationId: Get_JWT_Token
      parameters:
      - description: google plus oauth code
        in: formData
        name: gtoken
        type: string
      - description: login
        in: formData
        name: login
        type: string
      - description: password
        in: formData
        name: password
        type: string
      responses:
        "201":
          description: '...'
          schema:
            type: string
      summary: Get JWT token
      tags:
      - auth
  ...
```

<div id="app-front"/>

## Front-End

Весь фронт расположен в директориях `client` и `data`, при этом последняя директория генерируется за счёт `webpack`. Поэтому весь код для изменения или добавления следует размещать в `client`. Там же хранятся все роуты, компоненты и формы.

Проект написан на **`React.js`** и **`ECMAScript 6`**, что очень удобно и просто. Формы и большинство интерфейсных объектов фронта написаны с использованием **`Redux`**.

>***Замечание***: *при пересборке фронта не получится использовать вотчер `webpack`, потому что нужно полностью перегенерировать все файлы из `data` и пересобрать заново бинарник сервера. Это не очень удобно и занимает некоторое время, зато это не сильно сложнее, чем запустить вотчер:*

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/app
$ make serve
# пересборка сервера и запуск его с переменной среды DEVELOPMENT
$ ps aux | grep app-server | grep -v grep
# ... app-server PID ...
```

В головной директории лежат настройки линтера `eslint`, его необходимо запускать перед каждым пушем в репозиторий (подробнее в [CI](#wercker)):

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/app
$ ./.node_modules/.bin/eslint ./client
# запуск линтера по всему фронту, скорее всего будет >50000 критических ошибок
$ ./.node_modules/.bin/eslint --fix ./client
# скорее всего будет 0 критических ошибок
```

Подробнее про различные ключи можно [прочесть здесь][eslint-cmd].

<div id="fetcher"/>

## `Fetcher`

Сервис, который делает запросы к сайтам, которые парсятся. ***Все запросы делаются через proxy-сервер `Crawlera`, поэтому IP сервера не должен оказаться в бане*** (см. [TODO: разбан сервера](#crawlera)). Очень простой и понятный микросервис.

### Детали работы `Fetcher`

Сервис всегда слушает очередь `fetcher_rpc`, в которую поступают данные от сторонних сервисов при вызове метода `Call()` инстанса клиента сервиса `Fetcher`.

Основной функционал реализован в файле `server.go` и не является сложным. Функционал клиента лежит в пакете `client` и также простой.

>*С примерами можно ознакомиться в коде других сервисов (напр., [Indexer](#indexer)), из [других ReadMe](#other-readme) или с помощью следующей простой команды*:

```sh
$ find path_to_fetcher -maxdepth 2 -type f -name "*.md" | tail -1 | xargs less
# в открытом less будет присутствовать пример использования клиента
```

### Тесты `Fetcher`

**Тесты** для текущего репозитория **неполные**, но присутствуют. Желательно увеличить процент покрытия кода тестами. Тесты не требуют запуска с ключом `-race`

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/fetcher
$ go test -v ./client -run='.'
# простой запуск тестов для пакета `client`
```

<div id="importer"/>

## `Importer`

Сервис для импорта записей в систему. Сохраняет спарсенные данные в `Elastic Search`.

### Детали работы `Importer`

>***Замечание***: *я почти не работал с этим сервисом, поэтому не могу написать никаких особых деталей.*

Сервис публикует данные в очередь `actions` сервиса [IO](#io), скорее всего уже обработанные в `Elastic`.

Основные действия по обработке импортируемых записей происходят в одном файле `api.go` с множеством обращений к БД.

### Тесты `Importer`

В репозитории имеется несколько тестов для пакета `parser`, запускать обязательно с флагом гонки:

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/importer
$ go test -v -race ./parser -run='.'
```

<div id="indexer"/>

## `Indexer`

Сервис получает сообщения о действиях из очереди `actions` и начинает выполнение поступившего действия. Сервис, по сути, отвечает за работу ботов-парсеров.

### Детали работы `Indexer`

Репозиторий удобно разбит на множество пакетов для простоты работы:

- `generic` — **основной бот**, который получает данные от всех скраперов, создаёт инстанс загрузки в `Azure` и отправляет задание сервису [Scraper](#scraper) через сервис [IO](#io);
- `id12XXX` — пакеты с ботами, каждый бот должен удовлетворять интерфейсу `Runner` из пакета `types`. Метод `Run()` в каждом пакете запускает определённый пул скраперов из пакета `scrapers`, затем полученные результаты уже собираются `generic`-ботом. Каждая провинция (`county`) должна иметь определённое форматирование для загрузки, функции которого описаны в репозитории [Utils](#utils);

>***Совет***: *Для понимания того, за что отвечает определённый `id` в названии пакета, достаточно посмотреть таблицу `county` в базе данных `snl` на сервере.*

- `botutils` — содержит небольшой набор вспомогательных функций;
- `county` — содержит в себе `map[string]types.New`, с вызовом функции `New()` каждого пакета `id12XXX`, при объявлении нового пакета `id12XXX` — обязательно расширить мапу;
- `scrapers` — содержит в себе структуры определённых скраперов с соответствующими методами, которые парсят сайт(ы) и возвращают некоторые базовые результаты (напр., список `FolioID`);
- `upload` — содержит методы по созданию загрузки в `Azure` и  новой загрузки для вкладки `Property Data → Scraper → Uploads` на фронте;
- `config` — объёмный конфигурационный файл с настройками по каждой провинции, указаниеим сайтов, некоторых параметров форматирования, парсинга и т.д. **Требует самостоятельного ознакомления**!
- `main` — базовые методы по созданию слушателя, очереди, началу прослушивания очереди с задачами, созданию ботов и их запуску, простой и понятный пакет.

>***Совет***: *в этом репозитории имеется `README`, в котором просто и понятно показывается процесс создания нового бота. Рекомендуется к ознакомлению.*

### Тесты `Indexer`

В репозитории имеются базовые тесты под каждый пакет `id12XXX`, также имеется лишь 1 тест (*с двумя кейсами*) для пакета `scrapers`. При наличии времени желательно покрыть тестами пакет `scrapers`, чтобы понимать, изменилась ли структура сайта, который парсится, или где-то допущена ошибка разработчиком.

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/indexer
$ go test -v ./scrapers -run='.'
$ go test -v ./county... -run='.'
```

### **Индус в `Indexer`**

В этом репозитории также делал некоторые правки разработчик из Индии, например, написал скрапер `deceasedsearch.go`, некоторые изменения и дополнения в `main`.

Я избавился от нескольких ошибок и неточностей, допущенных им, но ошибки всё же могут присутствовать.

<div id="io"/>

## `IO`

Центральный сервис приёма и обработки входящих сообщений. Распределяет входящие сообщения очереди по остальным сервисам. Базово включает такие методы, как:

- `upload`;
- `export`;
- `delete`;
- `reindex`;
- `run_bots`;
- `restart`
- и некоторые другие.

### Детали работы `IO`

> ***Замечание***: *я довольно мало проработал с этим репозиторием, поэтому детали могут быть недетальными.*

По сути, основная цель сервиса — слушать `actions`, получать задание, если требуется, то обрабатывать его (*по этой причине присутствует множество различных файлов с вспомогательными функциями*) и передавать очередям других сервисов.

**Основные действия** сервиса описаны в файле `actions.go`.

### Тесты `IO`

>Тесты отсутствуют.

<div id="munroll"/>

## `Munroll`

>***Внимание***: *сервис является неработающим!*

Я не знаю функционал этого сервиса и его зону ответственности, код не изучал. Судя по основным методам — сервис работает примерно как [Importer](#importer) с какими-то изменениями.

### Тесты `Munroll`

Имеется минимальный набор тестов, **возможно**, они **устаревшие**.

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/munroll
$ go test -v -race ./preset/... -run='.'
$ if [ -f ./testdata/issues/extracted/check.csv ]; then go test -v ./ -run='.'; else echo "No test data"; fi
# что должно быть в файле check.csv — не могу знать, этот файл указан в gitignore
```

<div id="normalizer"/>

## `Normalizer`

Этот репозиторий должен отвечать за нормализацию поступивших данных (*owner and situs addresses, tax bills, folio appraisal, etc.*) и теоретически за то, чтобы эту информацию парсить с определённых сайтов.

<div id="normalizer-detail"/>

### Детали работы `Normalizer`

`Normalizer` не является полноценным сервисом (также как и [Preimport](#preimport-detail), см. [TODO: Normalizer as a Service](#normalizer-aas)). На текущий момент бинарник этого репозитория можно и не запускать, его функции частично или полностью выполняются в микросервисах [Indexer](#indexer) (*парсинг данных*) и [Scraper](#scraper) (*нормализация данных*).

Сервис необходимо переписать, хотя можно и полностью удалить его. Как минимум часть функций с [Scraper](#scraper) можно переложить на этот сервис.

### Тесты `Normalizer`

Имеются тесты аналогичные, как в [Scraper](#scraper-test)

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/normalizer
$ go test -v ./normalizers/... -run='.'
$ go test -v ./preimport/ -run='.'
```

<div id="preimport"/>

## `Preimport`

Этот репозиторий должен отвечать за предварительный импорт правил из пакета `preimport` (файл `rules.go`) и запускать соответствущего воркера. Как я понял, сервис нацелен на ускорение работы сервисов [Scraper](#scraper) и [Normalizer](#normalizer).

<div id="preimport-detail"/>

### Детали работы `Preimport`

`Preimport` не является полноценным сервисом. Его необходимо переписать (см. [TODO: Preimport as a Service](#preimport-aas)), чтобы был реализован механизм создания очереди при старте, корректная обработка данных и последующая отдача в соответствующий сервис.

В дополнение, необходимо будет развернуть [Dokku](#dokku) приложение.

>***Совет***: *свяжитесь с первым разработчиком или с клиентом для того, чтобы уточнить детали. Я не нашёл никакой информации об этом сервисе.*

Я немного переписал изначальный репозиторий, чтобы был хотя бы бинарник. **Работу бинарника не тестировал**.

### Тесты `Preimport`

Имеются тесты основного пакета `preimport`, которые проверяют корректность работы методов работы с правилами.

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/preimport
$ go test -v ./ -run='.'
```

<div id="scraper"/>

## `Scraper`

Сервис парсит некоторые данные (*situs and owner addresses, tax bills, folio appraisal, etc.*) с заданных сайтов, затем нормализует полученные данные и загружает в `Azure` и на сайт.

### Детали работы `Scraper`

**Сервис использует внутри себя 2 потенциально отдельных микросервиса ([Preimport](#preimport) и [Normalizer](#normalizer))**. Их требуется реализовать при возможности.

Сервис работает по простому алгоритму:

- получить из очереди `actions` данные `FolioID`;
- при необходимости форматировать их, используя функции форматирования из репозитория [Utils](#utils) (сидит в `vendor`);
- нормализовать записи (*owner and situs addresses, tax bills, folio appraisal, etc.*);
- выполнить `Preimport` при условии того, что пользователем был установлен соответствующий флаг;
- осуществить загрузку данных в `Azure` и в `background tasks`.

Процесс нормализации устроен примерно также как и запуск ботов в сервисе [Indexer](#indexer) — имеется `generic` нормализатор и деление по `county` с соответствующими форматами.

>***Замечание***: *не смотря на то, что процесс нормализации распараллелен хорошо, он всё равно является довольно медленным.*

**Временным, но рабочим, решением является увеличение ёмкости семафора `pool` до значений в 50-70, оптимальное значение не было найдено**.

Задачи из очереди распределяются в файле `router.go`, экспорт происходит в `export.go`, загрузка файлов описана в `upload.go` — все функции и методы в них являются простыми и не требуют дополнительного описания. Код в `xls/xls.go` является просто длинной обработкой всех столбцов для формирования выходного `*.XLSX` файла.

<div id="scraper-test"/>

### Тесты `Scraper`

В репозитории имеются тесты для внутреннего `preimport` пакета и пакетов по нормализации в директории `normalizers`.

>***Замечание***: *тесты имеются не для всех пакетов, имеющиеся содержат в себя по 1-2 кейсов, по возможности необходимо увеличить процент покрытия тестами всего сервиса и придумать больше кейсов, в особенности фейловых.*

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/scraper
$ go test -v ./normalizers/... -run='.'
$ go test -v ./preimport/ -run='.'
```

<div id="utils"/>

## `Utils`

Дополнительные функции для упрощения работы в микросервисах и работы с различными сторонними API.

### Детали работы `Utils`

>***Замечание***: *как водится, я практически не правил код в этом репозитории, а пакеты из него использовал редко, поэтому каких-то особых деталей не могу сказать.*

Имеются следующие пакеты и краткое описание

- `azure` — пакет для создания нового блоба и его заливки в облако `Azure`;
- `countries` — мапа со списком всех стран и их кратким кодом;
- `csv` — пакет по формированию и форматированию `*.CSV` файла для загрузки;
- `dates` — пакет для преобразования формата даты к типу времени `Open API` (`DateTime`);
- `format` — пакет по форматированию различных `counties`, содержит методы по форматированию `FolioID` и схемы их форматов;
- `names` — пакет форматирования имён владельцев, полученных с различных сайтов;
- `nlp` — пакет с «громким» названием, проверка схожести одного адреса с другим, используется в [Munroll](#munroll) и [Preimport](#preimport) (с сопуствующими сервисами в виде [Normalizer](#normalizer) и [Scraper](#scraper));
- `progress` — пакет для отображения процесса выполнения задачи, отображаемого на фронте;
- `queue` — пакет по упрощению работы с очередями [RabbitMQ], создаёт новых консьюмеров, паблишеров, сообщения и взаимодействие между ними;
- `sorting` — реализация интерфейса `Sort` стандартной библиотеки для сортировки записей [Scraper](#scraper);
- `states` — мапы по странам с их штатами/регионами, пополняемый;
- `zipcodes` — списки почтовых кодов различных стран, пополняемый.

<div id="utils-note"/>

>***Замечание***: *в данном репозитории вместе со всеми остальными репозиториями используется конкретная ревизия пакета [Azure][go-azure], ревизию можно заменить тогда и только тогда, когда будет обновлён пакет `azure`.*

### Тесты `Utils`

Имеются несколько тестов для различных пакетов с минимальным покрытием.

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/utils
$ go test -v ./nlp -run='.'
# пакет `nlp`
$ go test -v ./azure -run='.'
# пакет `azure`, является нерабочим до тех пор, пока не будут пофикшены кейсы или не переписаны тесты вообще при обновлении ревизии
$ go test -v ./format/ -run='.'
# пакет `format`
$ go test -v ./names/... -run='.'
# запуск тестов вложенных пакетов с `county`
$ go test -v ./ -run='.'
# бесполезный тест пакета `utils`
```

<div id="deploy"/>

## Deploy

Деплой осуществляется *автоматически* за счёт использования приложений [Dokku](#dokku) и [CI Wercker](#wercker).

<div id="wercker"/>

## CI `Wercker`

Проект работает на CI [Wercker][wercker-link], соответственно, имеются все настройки под запуск раннеров и последующего билда в каждом из репозиториев.

Файлы настроек лежат в корне каждого репозитория: `wercker.yml`.

Принцип работы как и у всех CI:

1. При пуше запускается раннер с описанными в настройках шагами.
2. Если пуш или мёрж был в одну из веток `master` или `develop`, запускается деплой в соответствии с настройками.

Деплой происходит простым пушем в репозиторий приложения [Dokku][dokku-link]. Подробнее о билде, билдпаках и приложениях см. раздел [Dokku](#dokku).

>***Совет***: *чтобы не зафейлить билд, рекомендую предварительно посмотреть на настройки CI в текущем репозитории, удостовериться, что на локалке всё билдится, все линтеры были прогнаны и тесты работают. Потом можно пушить в ветку.*

<div id="serverside"/>

## Сервер (DigitalOcean)

На сервере [DO][do-link] лежит проект с веткой `develop` и является `stage`-версией, однако в текущем виде ветка `develop` является основной для разработки, а `stage` является своего рода продакшеном.

>***Замечание***: ***ветку `master` можно спокойно смёржить с текущей веткой `develop`**, она проверена на работоспособность, с неё можно с нуля собрать проект и нет никаких препятствий для мёржа. Я его не делал по причине того, что заказчик не просил.*

Я обновлял сервер **15.01.2019**, так что все заголовки ядра и само ядро последней версии для `Ubuntu 16.04`. Также были обновлены некоторые плагины `Dokku` (за исключением `rabbitmq` и `postgresql` плагинов), сам `Dokku` обновлён до последней версии **0.8.\***, обновлён `Docker` до последней версии **18.09**.

Были спулены последние образы `Docker` для `rabbitmq` и `postgresql`, но они не были задеплоены (см. [TODO: Оркестрация](#swarm)).

<div id="dokku"/>

## `Dokku`

`Dokku` отвечает за деплой микросервисов на сервер `DO`. Сам деплой `Wercker` производит с помощью следующей команды:

```sh
$ git remote add server $GIT_REMOTE
# GIT_REMOTE — переменная окружения в настройках pipeline `Wercker`
$ git push server HEAD:master
# после пуша начинает работу buildpack
```

### Buildpack

В общем случае `Dokku` можно назвать [Heroku] на минималках. `Dokku` работает на билдпаках под эмуляцией `Heroku` с помощью утилиты [Herokuish].

Деплой почти всех приложений происходит с помощью одного [кастомного билдпака][buildpack-custom] для `Go`, который я держу в актуальном состоянии с апстримом.

Приложение `app` деплоится с помощью [мульти-билдпака][multi-buildpack], который уже использует мой для `Go` и использует [nodejs-buildpack] для сборки `nodejs` окружения.

Все репозитории настроены на использование:

- `dep` как менеджера пакетов
- версии `Go` **1.11.X** в билдпаке
- отказ от `dep ensure` из-за настроек приватности репозиториев на `bitbucket`
- в репозитории `APP` используется цель `heroku`, описанная в `Makefile`, **при её удалении приложение не будет задеплоено**

### Приложения

На текущий момент в `Dokku` задеплоены следующие приложения:

- `app` — сервер;
- `address`;
- `fetcher`;
- `importer`;
- `indexer`;
- `io`;
- `munroll`;
- `scraper`;
- `normalizer` — в рамках [начала перехода](#normalizer-detail) на микросервис.

```sh
$ dokku apps:list
# текущий список приложений
$ dokku ps:report
# текущее состояние всех приложений
$ dokku --help
# самая полезная команда
$ dokku COMMAND:help
# не менее полезная команда
```

Как было сказано, при переходе [Preimport](#preimport) на отдельный микросервис — **необходимо** будет **задеплоить новое приложение** для него. Создать своё приложение можно за несколько минут, более подробную информацию читать в [официальной документации][dokku-deploy-off] или [пошаговой инструкции][dokku-deploy-dummy].

### **Конфиг и переопределения**

Каждый репозиторий имеет свой собственный конфиг в пакете/файле `config(.go)`. Параметр конфига могут быть переопределены заданием параметров приложению `Dokku`.

**Общее правило** такое для приложения:

- все названия параметров `Dokku` заглавными буквами (uppercase);
- если параметр конфига является вложенным, то параметр `Dokku` должен иметь «_» перед каждым уровнем вложенности.

Пример:

```yaml
// config.go
config_parameter: 1
some:
  inner:
    parameter: true
```

Параметры приложения `Dokku` выглядят следующим образом:

```sh
$ dokku config app_name
# CONFIG_PARAMETER=1
# SOME_INNER_PARAMETER=true
$ dokku config:set [--no-restart] app_name MY_KEY1=MY_VALUE1 [MY_KEY2=MY_VALUE2]
```

Пример реальный:

```yaml
// config.go
debug: true //забыл выключить дебаг
rabbitmq:
  url: amqp://mmorgoev:password@localhost:5672/queue // забыл поменять локальный vhost
```

```sh
$ dokku config:set app_name DEBUG="false" RABBITMQ_URL="amqp://queue:d46d7f5dc52d9d0f6041b3f32a5d2151@stage.cpaulgroup.com:9969/queue"
# после рестарта приложения: дебаг выключен, rabbit работает
```

<div id="docker"/>

## `Docker`

Помимо приложений с сервером и микросервисами, на сервере `DO` запущены несколько контейнеров `Docker`:

- контейнер для `postgresql`;
- контейнер для `elasticsearch`;
- контейнер для `rabbitmq`;
- контейнер для `pgbouncer`.

>`pgbouncer` является [кастомным][pgbouncer-custom], детально я не успел разобрать изменения и отличия от [апстрима][pgbouncer-upstream].

В дополнение к указанным контейнерам имеются два [амбассадора][docker-amba] к `postgresql` и `rabbitmq`. Эта технология является устаревшей, но в данный момент времени она работает. В свободное время можно [выполнить переход](#swarm) на корректный метод взаимодействия контейнеров.

Все приложения `Dokku` общаются с указанными контейнерами, подключения контролирует `pgbouncer`.

<div id="build-main"/>

## Сборка, запуск, разработка

Для каждого репозитория я сделал `Makefile`, которые либо полностью запускают сборку, либо только проверяют наличие пакетов и запускают тесты.

**Установка и сборка проекта на локалке теперь предельно простая**.

<div id="prereq"/>

## Установка

### Предварительная настройка

Необходимые пакеты и их установка (пример на дистрибутиве `ArchLinux`):

- `rabbitmq`: `pacman -S --noconfirm rabbitmq`;
- `rabbitmqadmin`: `pacman -S --noconfirm rabbitmqadmin`;
- `yarn`: `pacman -S --noconfirm yarn`;
- `postgresql`: `pacman -S --noconfirm postgresql`;
- (опционально) `docker`: `pacman -S --noconfirm docker`;
- (опционально, я не ставил) `elasticsearch`: `pacman -S --noconfirm elasticsearch`.

#### `RabbitMQ`

```sh
# добавляем плагин для менеджмента
$ rabbitmq-plugins enable rabbitmq_management
# настройка rabbitmq пользователя
$ rabbitmqctl add_user user_name password
$ rabbitmqctl set_user_tags user_name administrator
# настройка vhost
$ rabbitmqctl add_vhost vhost_name
$ rabbitmqctl set_permissions -p vhost_name user_name ".*" ".*" ".*"
# настройка exchange (необязательно, я делал)
$ rabbitmqadmin declare exchange --vhost=vhost_name --user=user_name --password=password name=exchange_name type=direct durable=true
# настройка очереди (необязательно, я делал)
$ rabbitmqadmin declare queue --vhost=vhost_name --user=user_name --password=password name=queue_name durable=true
# биндим (необязательно, я делал)
$ rabbitmqadmin declare binding --vhost=vhost_name --user=user_name --password=password source=exhange_name destination=queue_name
# стартуем сервис
$ sudo systemctl start rabbitmq.service
# проверяем что всё ок
$ curl -i -u user_name:password http://localhost:15672/api/whoami
# опциональный запуск при старте компьютера
$ sudo systemctl enable rabbitmq.service
```

`RabbitMQ` можно настроить проще:

- [скопировав код][rabbit-setup], сделать его исполняемым и выполнить;
- выполнить:

```sh
$ docker pull rabbitmq
$ docker run -d --hostname rabbit_hostname --name docker.rabbit -p 5672:5672 -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -e RABBITMQ_DEFAULT_VHOST=vhost --net host rabbitmq:3.7.8-management
$ docker ps
# там будет контейнер, в нём rabbitmq запущенный и настроенный
```

#### `postgreSQL`

```sh
$ sudo systemctl start postgresql.service && sudo systemctl enable postgresql.service
$ sudo su - postgres
postgres $ initdb -D /var/lib/postgres/data
postgres $ psql
postgres=# \password
postgres=# CREATE USER user_name WITH PASSWORD 'password' SUPERUSER CREATEDB CREATEROLE;
postgres=# CREATE DATABASE snl OWNER user_name;
```

`postgreSQL` можно настроить проще:

```sh
$ docker pull postgres
$ docker run --name docker.postgres -e POSTGRES_PASSWORD=password -e POSTGRES_DB=snl -d postgres
$ docker ps
# там будет контейнер, в нём postgres запущенный и настроенный
```

<div id="build-project"/>

## Сборка проекта

Собирать проект ещё проще.

1. Сначала необходимо спулить все репозитории проекта, про которые написано в этой документации.
2. Выполнить для следующих репозиториев в указанной последовательности команду `make build`:

- `API`
- `Utils`
- `Address`

3. Для репозитория `APP` выполнить `make clean && make build`
4. Для всех остальных репозиториев выполнить `make build`
5. Для всех репозиториев, кроме `API` и `APP` выполнить сбилдить бинарники (`go build`)

>***Совет***: *можно [воспользоваться скриптом][rebuild] для билда и затем постоянно его использовать.*

>**Проект собран**.

### Запуск сервисов и сервера

**Запуск сервера**:

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/app
$ make serve
```

**Запуск сервисов** производится обычным запуском бинарника, при желании можно указать порт через ключ `--port`.

<div id="dep-work"/>

## Разработка в нескольких репозиториях

Все репозитории максимально облегчены за счёт `prune`-опций в манифесте `dep`.
>Исключение составляет репозиторий `APP`, где для пакета `bitbucket.org/dadebotsdb/api` указаны кастомные опции — необходимо, чтобы в `vendor` присутствовал файл `fixed.yaml`.

Почти везде во всех репозиториях я зафиксировал не конкретную ревизию или версию, а именно ветку. Там, где я фиксировал ветку — все изменения были обновлены и я уверен, что в ближайшее время обновления не поломают функционал.

> ***Совет***: *если что-то сломалось после `dep ensure -update`, то желательно откатиться, зафиксировать версию или даже ревизию какого-то пакета и затем продолжать работу.*

Все репозитории используют опцию `constraint` по-дефолту для каждого из пакетов, из-за этого могут иногда возникать проблемы при работе с несколькими репозиториями одновременно.

>***Пример***: идёт работа в репозиториях `API`, `APP` и `Indexer`, в каждом репозитории имеется ветка `feature/some_new`. Добавив новые модели в `API`, запушив изменения в текущую ветку, при попытке сделать `dep ensure` (*разумеется, заранее поменяв в манифесте ветку `develop` на `feature/some_new` у пакета `bitbucket.org/dadebotsdb/api`*) в любом из репозиториев — будет возникать ошибка. Это происходит из-за `constraint` на этот же проект в репозитории `Utils`, который указан с `constraint` в репозиториях `APP` и `Indexer`.

```toml
[[constraint]]
  name = "bitbucket.org/dadebotsdb/api"
  branch = "feature/some_new"
  source = "git@bitbucket.org:dadebotsdb/api.git"
```

>***Решение***: после пуша изменений `API`, поменять `constraint` для пакета `bitbucket.org/dadebotsdb/api` на `override`. Сделать `dep ensure`. Если после этого в ветку `feature/some_new` `API` будут запушены ещё какие-то изменения, то необходимо уже выполнить `dep ensure -update` в репозиториях `APP` и `Indexer`.

```toml
[[override]]
  name = "bitbucket.org/dadebotsdb/api"
  branch = "feature/some_new"
  source = "git@bitbucket.org:dadebotsdb/api.git"
```

**При возникновении любых вопросов по `dep`, можно обращаться [по этой ссылке][dep-dummy]**.

<div id="todo"/>

## TODO

Далее перечислены те пункты, которые я по каким-то причинам не успел сделать. Они не являются обязательными (кроме [разбана сервера](#crawlera)).

<div id="swarm"/>

## Оркестрация

Как было указано в секции [Docker](#docker), на сервере используется устаревшая архитектура связки контейнеров. Необходимо её обновить, воспользовавшись одним из предложенных вариантов.

### Варианты решения

Есть несколько вариантов:

1. [User-defined networks]
2. [Overlay networks]
3. [Configs]
4. [Stacks]

С моей точки зрения, самыми простыми вариантами являются 3 и 4. В любом случае, все варианты требуют создания [Swarm]. При начале работы желательно ознакомиться хотя бы с [базовыми примерами][swarm-man] работы со `Swarm`.

>Это задача для DevOps'а, особенно если выполнять работы непосредственно на сервере.

<div id="crawlera"/>

## Разбан сервера

Не смотря на то, что [Fetcher](#fetcher) работает через proxy-сервис [Crawlera], при частом запуске бота `RealTDM` был получен авто-бан, судя по всему, от `AWS`, на котором и хостится сайт. который парсится.

У меня не было возможности детально изучить проблему, возможно, что на текущий момент сервер уже не забанен.

### Варианты решения

1. Получить бан на локальном компьютере (я это уже сделал).
2. Пробросить end-point `Crawlera` на локалку, постучаться через proxy Crawlera на сайт.
3. Если сайт недоступен, то обратиться в [support-service][crawlera-support] `Crawlera`.
4. Если сайт доступен, то придумать решение проблемы.

**В любом случае необходимо в конфиге `Indexer` изменить значение `tdm.concurrentFetchEntries` с 25 на 5 или 10 (не больше)**.

<div id="preimport-aas"/>

## Preimport as a Service

Как [уже было описано](#preimport-detail), есть потребность перевести `Preimport` на отдельный сервис, избавившись от дубликатов директории этого репозитория в сервисах `Scraper` и `Normalizer`.

*Скорее всего эту задачу надо делать совместо со следующей задачей*.

### Варианты решения

1. Выяснить зачем конкретно нужен `Preimport`.
2. Реализовать воркера, корректную работу пула с очередями, возможно, какую-то обработку.
3. [Создать приложение][dokku-deploy-off] в `Dokku`.

<div id="normalizer-aas"/>

## Normalizer as a Service

Аналогично предыдущему пункту. Как [уже было описано](#normalizer-detail), есть потребность перевести `Normalizer` на отдельный сервис.

>Либо можно полностью избавиться от этого репозитория, в этом случае нагрузка на `Scraper` будет сохраняться и замедлять его работу.

### Варианты решения

1. Реализовать корректную работу нормализации (можно взять из `Scraper`), создать свои очереди, наладить общение между микросервисами.

Приложение в `Dokku` уже существует.

<div id="paper-logger"/>

## Включить PaperTrail

Заказчик не успел оплатить аккаунт на [PaperTrail], поэтому после перехода на этот логгер, я выключил логирование в сервис.

### Варианты решения

1. Заменить в конфигах всех репозиториев `papertrail:.use: false` на `papertrail.use: true`.

<div id="other-readme"/>

## Другие README

Во многих репозиториях присутствуют файлы `README`, которые являются как устаревшими (например `README` в пакете `queue` репозитория `Utils`), так могут и **содержать полезную информацию** (например, `README` в `Indexer`).

Здесь я просто сообщаю о том, что есть какая-то техническая документация, которую у меня не было времени обновить. Найти все `README` нетрудно:

```sh
$ pwd
# $GOPATH/bitbucket.org/dadebotsdb/
$ find -not \( -path "*vendor*" -prune \) -name "README.md" -print
```

[//]: # (Секция комментариев)

   [dep-link]: <https://github.com/golang/dep>
   [swagger-blog]: <https://posener.github.io/openapi-intro/>
   [swagger-off]: <https://swagger.io>
   [swagger-editor]: <https://editor.swagger.io>
   [eslint-cmd]: <https://eslint.org/docs/user-guide/command-line-interface>
   [go-azure]: <https://github.com/Azure/azure-sdk-for-go>
   [wercker-link]: <https://app.wercker.com>
   [dokku-link]: <http://dokku.viewdocs.io/dokku/>
   [dokku-deploy-off]: <http://dokku.viewdocs.io/dokku/deployment/application-deployment/>
   [dokku-deploy-dummy]: <https://glebbahmutov.com/blog/running-multiple-applications-in-dokku/>
   [buildpack-custom]: <https://github.com/zerospiel/heroku-buildpack-go>
   [multi-buildpack]: <https://github.com/heroku/heroku-buildpack-multi.git>
   [nodejs-buildpack]: <https://github.com/heroku/heroku-buildpack-nodejs.git>
   [do-link]: <https://cloud.digitalocean.com>
   [pgbouncer-custom]: <https://github.com/toscale/pgbouncer>
   [pgbouncer-upstream]: <https://github.com/brainsam/pgbouncer>
   [docker-amba]: <https://docs.docker.com/config/thirdparty/ambassador_pattern_linking/>
   [rabbit-setup]: <https://gist.github.com/fforbeck/868462c0f7664d92e19e>
   [rebuild]: <https://gist.github.com/zerospiel/8c877629dab9cd538560ae1c0775643f>
   [dep-dummy]: <https://github.com/golang/dep/blob/master/docs/Gopkg.toml.md>
   [crawlera-support]: <https://scrapinghub.com/contact>
   [swarm-man]: <https://docs.docker.com/get-started/part4/>
   [RabbitMQ]: <https://www.rabbitmq.com>
   [SmartyStreets]: <https://smartystreets.com>
   [Google Maps]: <https://cloud.google.com/maps-platform/>
   [YAddress]: <https://www.yaddress.net>
   [SQLMigrate]: <https://github.com/rubenv/sql-migrate>
   [Go-Swagger]: <https://github.com/go-swagger/go-swagger/cmd/swagger>
   [Go-Bindata]: <https://github.com/jteeuwen/go-bindata/>
   [Heroku]: <https://www.heroku.com>
   [Herokuish]: <https://github.com/gliderlabs/herokuish>
   [Crawlera]: <https://scrapinghub.com/crawlera>
   [User-defined networks]: <https://docs.docker.com/engine/userguide/networking/#user-defined-networks>
   [Overlay networks]: <https://docs.docker.com/engine/userguide/networking/overlay-security-model/>
   [Configs]: <https://docs.docker.com/engine/swarm/configs/>
   [Stacks]: <https://docs.docker.com/get-started/part5/>
   [Swarm]: <https://docs.docker.com/engine/swarm/>
   [PaperTrail]: <https://papertrailapp.com>